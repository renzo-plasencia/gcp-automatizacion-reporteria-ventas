# Proyecto: Automatizaci√≥n de KPIs
## **Contexto:** 

Actualmente el equipo comercial de una empresa financiera üè¶ genera reportes diarios sobre nivel de ventas, ventas diarias, concentraci√≥n geogr√°fica de ventas y clientes a quienes m√°s se le ha vendido en los √∫ltimos 3 meses.

Esta informaci√≥n es consumida por diferentes analistas. Estos ejecutan diariamente un conjunto de querys para obtener la informaci√≥n.

La principal problem√°tica est√° en que no se cuenta con un hist√≥rico de KPIs organizado (una carpeta con todos los archivos de forma hist√≥rica); adem√°s, se sigue corriendo de forma manual desde BigQuery.

## **Soluci√≥n**

La soluci√≥n planteada es crear un proceso en *Cloud Function* con *Cloud Scheduler* que permita generar de forma autom√°tica y programada los reportes en una ruta pre definida y a una hora espec√≠fica.

## Arquitectura Cloud



---
***Nota:** Es un caso simulado, la informaci√≥n es dummy. Se busca demostrar el uso de Cloud Function principalmente.*

# Obtener fuente de datos
Si quieren obtener la fuente de datos con la que realic√© el ejercicio lo pueden obtener desde Kaggle.

## Descargar informaci√≥n

Descargar el **dataset** desde Kaggle.
```powershell
curl -L -o %USERPROFILE%/Downloads/ecommerce-data.zip  https://www.kaggle.com/api/v1/datasets/download/carrie1/ecommerce-data
```

Descomprimir la informaci√≥n
```bash
tar xf "amazon-sales-dataset.zip"
```

## Limpiar y subir informaci√≥n a Bigquery
Prepara la subida de informaci√≥n como dataset principal. Se subir√° en GCP.

```Python
!pip install --upgrade google-cloud-bigquery pandas pyarrow

from google.colab import auth
auth.authenticate_user()
print("‚úÖ Autenticado correctamente")
```
C√≥digo para procesar y limpiar la informaci√≥n

```Python
import pandas as pd
path = 'data.csv'
dict_names = {'InvoiceNo': 'nro_factura',
              'StockCode': 'codigo_producto',
              'Description': 'descripcion_producto',
              'Quantity': 'cantidad_vendida',
              'InvoiceDate': 'fecha_factura',
              'UnitPrice': 'precio_unitario',
              'CustomerID': 'id_cliente',
              'Country': 'pais_cliente'
              }

data_types = {
    'InvoiceNo': 'string',
    'StockCode': 'string',
    'Description': 'string',
    'Quantity': 'float64',
    'InvoiceDate': 'string',
    'UnitPrice': 'float64',
    'CustomerID': 'string',
    'Country': 'string'
}

df = pd.read_csv(path,
                 delimiter=',',
                 encoding='latin1',
                 dtype=data_types,
                 parse_dates=['InvoiceDate']
                 ).rename(columns=dict_names)

# Quitar la hora
df['fecha_factura_sin_hora'] = df['fecha_factura'].dt.date
# Agregar periodo
df['periodo'] = df['fecha_factura'].dt.strftime('%Y%m')
```

Subir informaci√≥n a BigQuery
```Python
from google.cloud import bigquery

project_id = "proyecto-ventas-diarias"
dataset_id = "ventas"
table_id   = "ventas-diarias"

client = bigquery.Client(project=project_id)
table_ref = f"{project_id}.{dataset_id}.{table_id}"

job = client.load_table_from_dataframe(df, table_ref)
job.result()

print(f"‚úÖ Datos cargados correctamente en {table_ref}")
```

Con esto tendr√°s disponible la fuente de datos que use.

# Querys para generaci√≥n de reporter√≠a (KPI)
Son querys b√°sicas que nos permitir√°n obtener la informaci√≥n para construir KPI de ventas b√°sicos.

``` SQL
-- Ventas mensuales (precio unitario * cantidad)
SELECT Periodo, SUM(cantidad_vendida * precio_unitario) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias`
group by periodo;

-- Ventas diarias acumuladas
SELECT fecha_factura_sin_hora, SUM(cantidad_vendida * precio_unitario) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias`
group by fecha_factura_sin_hora;

-- Top 3 pa√≠ses con m√°s ventas en el √∫ltimo periodo
SELECT pais_cliente,round(SUM(cantidad_vendida * precio_unitario),2) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias` 
WHERE Periodo = (SELECT MAX(periodo) FROM `proyecto-ventas-diarias.ventas.ventas-diarias`) and cantidad_vendida > 0
GROUP BY pais_cliente;

-- Cliente con compras superiores a 1000 en el √∫ltimo periodo
WITH CTE_VENTAS_X_CLIENTE AS (
  SELECT periodo,id_cliente, round(SUM(cantidad_vendida * precio_unitario),2) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias` 
  group by periodo,id_cliente 
) SELECT ID_CLIENTE,ROUND(SUM(PRECIO_TOTAL),2) FROM CTE_VENTAS_X_CLIENTE
WHERE PERIODO = (SELECT MAX(periodo) FROM `proyecto-ventas-diarias.ventas.ventas-diarias`) and precio_total > 1000
GROUP BY ID_CLIENTE
;
```

---
# Configuraci√≥n y c√≥digo
## Configuraci√≥n Cloud Function

## C√≥digo Cloud Function
``` python
import functions_framework
import pandas as pd
from google.cloud import bigquery,storage
from datetime import datetime

@functions_framework.http
def main(request):    
    # Nombre de la tabla SQL
    project_id = "proyecto-ventas-diarias"
    dataset_id = "ventas"
    table_id   = "ventas-diarias"

    # Nombre del bucket
    bucket_name = "ventas-diarias-bucket"
    folder = "reporte-diario-ventas"

    # Crear cliente bigquery y storage
    bq_client = bigquery.Client(project=project_id)
    storage_client = storage.Client()

    query_1 = """
    SELECT Periodo, SUM(cantidad_vendida * precio_unitario) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias` group by periodo;
    """

    query_2 = """
    SELECT fecha_factura_sin_hora, SUM(cantidad_vendida * precio_unitario) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias` group by fecha_factura_sin_hora;
    """

    query_3 = """
    SELECT pais_cliente,round(SUM(cantidad_vendida * precio_unitario),2) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias` WHERE Periodo = (SELECT MAX(periodo) FROM `proyecto-ventas-diarias.ventas.ventas-diarias`) and cantidad_vendida > 0 GROUP BY pais_cliente;
    """

    query_4 = """
    WITH CTE_VENTAS_X_CLIENTE AS (
    SELECT periodo,id_cliente, round(SUM(cantidad_vendida * precio_unitario),2) as precio_total FROM `proyecto-ventas-diarias.ventas.ventas-diarias` 
    group by periodo,id_cliente 
    ) SELECT ID_CLIENTE,ROUND(SUM(PRECIO_TOTAL),2) FROM CTE_VENTAS_X_CLIENTE
    WHERE PERIODO = (SELECT MAX(periodo) FROM `proyecto-ventas-diarias.ventas.ventas-diarias`) and precio_total > 1000
    GROUP BY ID_CLIENTE
    ;
    """

    df = bq_client.query(query_1).to_dataframe()
    df_2 = bq_client.query(query_2).to_dataframe()
    df_3 = bq_client.query(query_3).to_dataframe()
    df_4 = bq_client.query(query_4).to_dataframe()

    dataframes = [df,df_2,df_3,df_4]

    fecha_actual = datetime.now().strftime('%Y%m%d')
    bucket = storage_client.bucket(bucket_name)

    for i,dfx in enumerate(dataframes,start=1):
        file_name = f"REPORTE_{i}_KPI_{fecha_actual}.csv"
        blob = bucket.blob(f"{folder}/{file_name}")
        blob.upload_from_string(dfx.to_csv(index=False, sep=";"), content_type="text/csv")

        print(f"‚úÖ Archivo subido: gs://{bucket_name}/{folder}/{file_name}")
    
    return f"‚ö†Ô∏è Se termin√≥ la carga de los archivos. gs://{bucket_name}/{folder}"
```

## Configuraci√≥n IAM

## Im√°genes del resultado Final


Configuracion de IAM ...
Basada en solicitudes
0 instancias (no es importante una respuesta rapida), asi que puede arrancar en frio?

